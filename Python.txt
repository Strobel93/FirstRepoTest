###########################################
Styleguide PEP8
###########################################
if check_is_true:
if check is None:
switch1,switch2 = switch2,switch1
v1, __, ext = 1,2,3 # Ignoring value 2
white_spacing = [0, 1, 2]
ClassNames():
variable_names =
CONSTANT_NAMES =
function_names():
multi_line_style = (    # () > \ for line breaking
    "line 1"
    "line 2"
    )
###########################################
#Import: any directory with an __init__.py (empty/comments/imports) file is considered a Python package
###########################################
import python_Datei_komplett
from Python_Datei import funktion
from Python_Datei import Klasse
from Order.Python_Datei import Funktion
from Python_Datei import (file1,file2,file)
from .currenfolderDatei import Klasse

###########################################
#Schreibweisen
###########################################
def small_letters(v1: Datatype,v2: Datatype = None) ->returndatatype:
	print('FU')
	
for x in range(n, 0, -1):
    print(x)
	
x += 2
x *= 2
###########################################
import copy
###########################################
# shallow copies: same object (id), changs effect to one, effect both
# deep copies: differnet object (id), changes to one, dont effect the other
# list
shallow = list_v
deep    = copy.deepcopy(list_v)
	
###########################################
#Functionsexectioon handling
###########################################	
def func1(p1):
    print(p1)


def func2(p1, p2):
    print(p1, p2)


def func_handler(func, *args):
    func(*args)


func_handler(func1, 1)
func_handler(func2, 1, 2)

####################################################################################################
#Callable: erlaubt dynamische anwendung bzw, aufruf von Funktionen/Formeln
####################################################################################################
from typing import Callable

def add(a, b):
    print(a + b)

def sub(a, b):
    print(a - b)

def call_example(f: Callable, a, b):
    return f(a, b)

call_example(add, 5, 3)
call_example(sub, 5, 3)
print(call_example(lambda x, y: x * y, 5, 3))

#######################################
#Strings
#######################################
x = 69
y = 420
s = 'kek {}'.format(x)
s = 'kek {0}{1}{0}'.format(x,y)
s = 'kek {s1}{s2}{s1}'.format(s1=x,s2=y)
  
####################################################################
#Collections Named tupple
####################################################################
from collections import namedtuple
Animal = namedtuple('Animal', 'name age type')
perry = Animal(name="perry", age=31, type="cat")
perry.age
 
###################################
#set = distinct 
###################################
set_bsp = {1,2,3,3,4}

###################################
#Dictionary
###################################
dick = {'size': 5, 'color': 'white'} #gef�llte Liste erzeugen
print(dick['size'])
print(dick.items)
print(dick.keys) 
print(dick.values) 
print('size' in dick)
print(5 in dick.values())

###################################
#Nested Dictionary
###################################
people = {'eins': {'name': 'John', 'age': '27', 'sex': 'Male'},
          'zwei': {'name': 'Marie', 'age': '22', 'sex': 'Female'}}

#Abruf
print(people['eins']['name'])

###################################
#Array: import numpy as np
###################################
# Arrayerzeugung
x = np.array(list)
x = np.full((5,5),None)					#5x5 with defaultvalue
x = np.zeros((5,5))						#5x5 with zeros
x = np.random.randint(0, 100, 5)		#5 numbers from 0-100
x = np.random.randint(0, 100, (5,5))	#5x5 numbers from 0-100
x = np.arange(0, 20)					#0-19
x = np.arange(1,10).reshape(3,3)		#3x3 range  

##################################################################################
#Slicing [a:b:c]/slice(a,b,c) = [von:bis:Schritt] 
##################################################################################
#C hat Dimensionalit�t von 4:2:3 (4 Arrays, mit je 2 Arrays L�nge, mit je 3 Elementen
#Slicing-->0 nicht f�r Anfang und len(a) nicht f�r ende w�hlen[:N],[N:]
print(c[:])
print(c.shape)
print(c[0][1][1])   #Array 1, Subarray 2, Position 2
print(c[0, 1, 1])   #Array 1, Subarray 2, Position 2
print(c[0,[3,2,1])	#Array 1, Element 3, 2, 1
print(c[:,:,0])     #Alle ersten Positionen jedes Subarrays
print(c[:,0,:])     #Alle ersten Subarrays aller 4 Arrays
print(c[0,::])      #Ganze erste Array    
#R�ckwerts --> stepsize -1
print(s[::-1])
all_but_last_n = x[:-2]
only_last_n = x[-5:]

# Concatinating
#[[a1],[a2],[b1],[b2]]
np.concatenate([x1, x2])
np.vstack((x1, x2))
np.append(x1, x2)

#[[a1+b1],[a2+b2]]
np.concatenate((a, b), axis=1)) 
np.hstack((a,b)))

# UFuncs (Universal functions, faster than iterating over whole array)
# operated on all values in array, operators (+-*...) are wrappers for numpy implementations np.add()
add_1_to_all = x1 + 1
minus_same_index = x1 - x2
minus_only_certain = x1[0:2] - x2[0:2]
aggregate_whole_ar = np.multiply.reduce(x1)
aggregate_whole_ar = np.sum(x1)
maximum_in_whole_ar = np.max(x1)
maximum_by_column = x1.min(axis=1)
maximum_by_row = x1.min(axis=0)
true_false_for_each = x1 < 3
true_false_for_each = x1 == 3
tf_any_value_matching_condition = np.any(x1 < 5)
tf_all_value_matching_condition = np.all(x1 < 5)
conditional_sum = np.sum(x1 < 3)
conditional_sum = np.sum(x1 > 10) & (x1 < 5)
filter_with_true_false = x1[x1 < 3]
if_else_pro_element = np.where(x1 > x2, x1, x2)

# General:	              
arr.flatten() # returns deep flattend copy
arr.ravel()   # returns a shallow flattend copy
a.sort()
new_sorted_list = np.sort(a)
sorted_subarrays = np.sort(a, axis=1)
# returns array of a's indexes reordered, if that index order was used, a would be ordered  [69,1,420] --> [1,0,2]
np.argsort(a)			
# sort nested array by index x: get order by argsort, output array with indexes outputted by argsort		 
nested_sorted_by_index = a[np.argsort(a[:, x])]

#Inner Join mit Array
a = np.array([1,2,3,4])
b = np.array([3,4,5,6])

print(np.intersect1d(a,b))
print(a[np.in1d(a, b)])

###################################
#Series import pandas as pd
###################################
#V1
fruits = ['apples', 'oranges', 'cherries', 'pears']
quantities = [20, 33, 52, 10]
s = pd.Series(quantities, index = fruits)

#V2
d = {'b': 1, 'a': 0, 'c': 2}
pd.Series(d)

second_index_value 		= s[1]
value_by_index 			= s['apples']
value_by_condition		= s[s>20]
values_by_ind_slice 	= s[0:2].values
keys_by_ind_slice		= s['apples':'cherries'].keys()

###################################
#Dataframe: import pandas as pd
#Dataframe besteht aus N panda Series
	--> Seriesfunktionen f�r DF Spalten verwendbar
	--> df["Column"] == Series
###################################
import pandas as pd
axis = 0 --> �ber alle Zeilen  (1x average pro Spalte)
axis = 1 --> �ber alle Spalten (1x average aller numerischen Werte dieser Zeile)

#########################
# Creation
##########################
# 4x4 DF with random Numbers between 0,69
a = pd.DataFrame(rng.randint(0, 69, (4, 4)),
				 columns=['c1','c2', 'c3', 'c4'])

ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',
		   'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],
		   'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],
		   'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],
		   'Points':[876,789,863,673,741,812,756,788,694,701,804,690],
		   'Points2':[8761,19,8613,73,7141,8112,56,7818,94,7101,8104,6910]
		}
#Index
indexes = ['a','b','c','d','e','f','g','h','i','j','k','l']
df = pd.DataFrame(data=ipl_data,index=indexes)
indexes.set_index('C1', Inplace=True)
multi_indexed_DF.index.names = ['first_ind','second_ind']
multi_indexed_DF.set_index(['C1','c2','c3'], Inplace=True)
 
#�bersich �ber Dataframe: count, mean, min,max,.. (stackable ontop each other)
#Counter z.B. n�tzlich f�r fehlende Werte
#funktionieren auch auf spalten df[Year].isnull(), df.Year.isnull()
df.describe()
df.columns
df.corr()
df.isnull()
df.notnull()
df.dropna()
df.fillna()
total_nulls_each_Colum = df.isnull().sum()
df.column.duplicated()
df.unstack()	#PIVOT/UNPIVOT
df.pivot_table(Index=['column1'] 		# column of whichs DISTINCT values become rows of first column
              ,columns = ['column2']	# each DISTINCT Value becomes a different column appended to first column (wide table)
			  ,values = 'column3')		# each column2 column gets a value  based on match on between c1, c2, c3 (sparse table)
df['column'] = df.column.str.lower()
df['column'].apply(lambda: x: x.upper())
df['Teams'].quantile(q=[0.25,0.5,0.75])
df['Teams'].value_counts()

#Columausgabe/Zugriff
print(df.Points)
print(df["Points"].values)
print(df[["Year","Points"]])

#Ausgabe mit Und und True False --> true werte ausgegeben 
tf2 = (df['Year']==2016) | (df['Year']==2017)
print(df[tf2]) 

#Query, soadss gesehen mit @ tag f�r variablen
bsp = 2016
print(df.query('Year == @bsp' & Team = 'Kings'))
print(df.query('Team == "Kings"'))

#Between/isin
tf4 = df['Year'].between(2014,2016)
tf4 = df['Year'].isin([2014,2015,2016])

#loc/iloc (indexlocator) Struktur immer: [Rows or Index, Columns]
print(df.loc[['a','b'],['Team','Rank','Year']])
print(df.loc['a':'d'],['Team','Rank','Year']])
print(df.loc[tf4,['Team','Rank','Year']]) #True/False f�r Row Filter
print(df[(df['Year']<=2015)])
print(df[df.Year <= 2015])
print(df[df['Year'].notnull()])
print(df[df.Year == 2015]['Rank'])
print(df.loc[(df['Year']<=2015),['Team','Rank','Year']])
print(df.loc[(df.Year <= 2015),['Team','Rank','Year']])

print(df.iloc[[0,1],[0,1,2]])
print(df.iloc[0:4,[0,1,2]])

#Sort by regualar column/columns
print(df.sort_values(by='Year', ascending=False))
print(df.sort_values(by=['Team','Year'], ascending=False))

#Sort und Top 10 by Aggregated Column
grp = df.groupby(['Team']).agg({'Points':sum}).sort_values(ascend='False')
grp = df.groupby(['Team']).agg({'Points':sum}).sort_values(ascend='False').head(10)
grp = df.groupby(['Team'])

#Beispiel
print(df[(df['Year']<=2015)].groupby(['Team','Year'])['Points'].sum())
print(df[(df['Year']<=2015)].groupby(['Team','Year']).agg({'Points':sum}))
print(df[(df['Year']<=2015)].groupby(['Team','Year']).agg({'Points':sum, Points2: [min, max]}))
print(df.loc[df["Points"] >= df["Points"].mean()])
print(df[(df['Year']<=2015)].groupby(['Team','Year']).agg(count('Year'))).alias(�Counter Column�)
print(df.groupby(listname)])
print(df.groupby(df[])])

# Concats
row_append_ax0 = pd.concat([df1, df2])
ra_ax0_continious_index = pd.concat([df1, df2], ignore_index= True)
column_app_ax1 = pd.concat([df1, df2], axis = 1)
df1.append(df2)

#Joining
df_inner_join = pd.merge(df1,df2, on=['joincolumn1','JC2'], how='inner') --right,left,outer
diff_column_names = pd.merge(df1, df2, left_on ='name_jc_of_df1', right_on = 'name_jc_of_df2')
index_join = pd.merge(df1, df2, left_index = True, right_index = True)
inner_join 	  = series1.join(series2, how='left') #Join basierend auf selben Indexen

#Datumsfunktionen
print(df['datecolumn'].dt.year)
print(df['datecolumn'].dt.month)

#Lag Lead 
#1 Wert R�ckwirkend auslesen -->aus Zeile N Zeilen zur�ck 
print(df['Year'].shift(1))
print(df['Year'].shift(365))

#Ausgabe Aggregation aus allen N letzten Werten
print(df['Year'].rolling(window = 2).mean())
print(df['Year'].rolling(window = 5).max())

#####################################################################################################
# Multi/Hierarchical Indexing: data + index + creation
# Create DF with hierarchal index directly or create DF and change columns to indexes
#####################################################################################################
# V1:
multi_indexed_DF = pd.DataFrame(np.random.rand(4, 2),
								index=[['a', 'a', 'b', 'b'], [1, 2, 1, 2]],
								columns=['data1', 'data2'],)

# V2:
mult_index = [('index1', 2000), ('index1', 2010),
              ('index1', 2000), ('index1', 2010),
              ('index1', 2000), ('index1', 2010)]
mult_index = [['Cal', 'NY', 'NY', 'Tex', 'Tex', 'Tex']
    		  ,[2000, 2001, 2000, 2002, 2000, 2010]]

populations = [33871648, 37253956,
               18976457, 19378102,
               20851820, 25145561]
u_18 = [9267089, 9284094,
		4687374, 4318033,
		5906301, 6879014]

multi_indexed_DF = pd.DataFrame({
									 'string_column': ['a', 'b', 'c', 'd', 'e', 'f']
									,'total': populations
									,'under18': u_18
								 }
									,index=mult_index)
# indexing: renaming + changing columns to indexes themselves
multi_indexed_DF.index.names = ['first_ind','second_ind']
multi_indexed_DF.set_index(['C1','c2','c3'], Inplace=True)

# Slicing/Dicing hierachical: loc[(index1,index2),[columns]]
# Slicing [x:y] only works with sorted indexes 
sorted = df._sort_index()
column_selection     = multi_indexed_DF[['data1', 'data2']]
column_selection     = multi_indexed_DF.loc[['a','b']]
loc_iloc_select      = multi_indexed_DF.loc[['a','b'][0]]
fil_mlt_index_levels = multi_indexed_DF.loc[('a', [1,2]), ['data1','data2']]
fil_mlt_index_levels = multi_indexed_DF.loc[(['a','b'], 1), ['data1','data2']]
value_filter     = multi_indexed_DF.loc[multi_indexed_DF.data1 > 0.5]
value_filter     = multi_indexed_DF[multi_indexed_DF.data1 > 0.5]

#################################################
#Edit Dataframes
#################################################
#Dataframe Cleaning: 
#Unn�tige Spalten
df.drop.(colums=['column1','column2'])

#Unn�tige Zeilen, drop Zeile 1 und 3
df.drop([1, 3])
df.drop(df.index[[1,3]])

df.dropna(axis=1, how='all')    		#Spalten/Zeilen wo alle Werte NaN
df.dropna(axis=1, how='any')    		#Spalten/Zeilen mit mit min 1 Nan
df.dropna(axis=1, how='all', thresh=3)  #Threshold = min number of non nun values to be kept

#Alle Daten �ndern
df["Points"]=df["Points"]*100
df.Points = df["Points"]*100
df['Points2'] = df['Points']*df['Points']
df['new_col'] = df['Points']*df['Points']
df['Points']=df['Points'].apply(lambda x: x*2)
df.Points=df['Points'].apply(lambda x: x*2)

#Bestimmte Zeilen �ndern
df['a'][0] = 69
df.loc['Row','Column'] = 420
df.iloc[0,0] = 420
df.loc[df.Year==2015,"Points"] = df["Points"]*100
df.loc[df.Year==2015,"Points"]=df['Points'].apply(lambda x: x*x)
df['Points'] = np.where(df['Year']==2015, df["Points"]*100, df["Points"])
 
#Select: matching condition 1 mit choice 1, co2 mit ch2,..
conditions 	    = [(df.Year == 2015),(df.Year == 2014)]
choices    		= ["2015","2014"]
df["new_column"]=np.select(conditions,choices,"default")
 
#Fehlende Werte f�llen
df['Points'].fillna(df['Points'].mean(),inplace= True)
df.Points.fillna(69)
df['a']=df['a'].replace(0,df['a'].mean())

#String replace f�r .apply function, a zu nichts
df['Column'].replace('A','')

###################################
#df.apply --> Custom functions
###################################
def funktion(row):
    if row == 2014:
        return "2014"
    else:
        return "Nicht 2014"

df["new_Column2"] = df["Year"].apply(funktion)

#Axis: 0 apply to all Columns, 1 to all Rows
#Sum Columns
print(df.apply(np.sum))
print(df.apply(np.sum, axis=0))
#Sum Rows
print(df.apply(np.sum, axis=1))

#################################################
#Datasets for testing
#################################################
x, y = datasets.load_iris(return_X_y=True)
dataset = datasets.load_iris()
x = dataset.data
y = dataset.target
sns.load_dataset("iris")

#################################################
#Matplotlib
#################################################
import matplotlib.pyplot as plt

plt.diagramm(xAchsenDaten,yAchsenDaten,yAchsenDaten2)
plt.diagramm(df.column)
plt.plot(x,y)
plt.bar(x,y)
plt.scatter(x,y)

#3D
ax = plt.axes(projection='3d')
ax.plot3D(x_axis, y_axis, z_axis) 

#############################################
#Plot 3 Graphs in same cordinate System
#############################################
months = range(1, 13)
nyc_temp_2000 = [31.3, 37.3, 47.2, 51.0, 63.5, 71.3, 72.3, 72.7, 66.0, 57.0, 45.3, 31.1]
nyc_temp_2006 = [40.9, 35.7, 43.1, 55.7, 63.1, 71.0, 77.9, 75.8, 66.6, 56.2, 51.9, 43.6]
nyc_temp_2012 = [37.3, 40.9, 50.9, 54.8, 65.1, 71.0, 78.8, 76.7, 68.8, 58.0, 43.9, 41.5]

#All(appending different x-axis next to each other vs same x-axis) vs Individual
plt.plot(months, nyc_temp_2000,months, nyc_temp_2006,months, nyc_temp_2012)
plt.plot(months, nyc_temp_2000)
plt.plot(months, nyc_temp_2006)
plt.plot(months, nyc_temp_2012)
plt.show()
  
#############################################
#Mehrere Graphen unter/nebeneinander Subplots
#############################################
#Single Subplot (with optional multiple graphs)
fig, ax = plt.subplots()
ax.plot(x, y)
ax.plot(x, y2)
plt.show()
 
#2 Below each other
#Erzeugen von 2 graphen untereinander, einer mit negativen Y Werten
fig, axs = plt.subplots(2)
axs[0].plot(x, y)
axs[1].plot(x, -y)
 
#Erzeugt 2 Grafiken, aber nebeneinander, version mit direktbezeichnung statt indexiertem Aufruf
fig, (ax1, ax2) = plt.subplots(1, 2)
ax1.plot(x, y)
ax2.plot(x, -y)

#2x2 Grafiken
fig, axs = plt.subplots(2, 2)
axs[0, 0].plot(x, y)
axs[0, 1].plot(x, y, 'tab:orange')
axs[1, 0].plot(x, -y, 'tab:green')
axs[1, 1].plot(x, -y, 'tab:red')

#Config: plt.function() --> ax.set_function()
fig.suptitle('whole_graphic_title')
ax.plot(x, y, color = 'red')
ax.plot(x, y, label='y_value_description')
ax.set_title('subplot_title')
ax.set_xlabel('sub_x_label')
ax.set_ylabel('sub_y_label')
plt.title('Diagrammtitel')
plt.xlim(0,69)
plt.ylim(0,420)
plt.show()

# Stylesheets 
# used for whole session, set at beginning
plt.style.available[:5]
plt.style.use('grayscale')

#Use Seaborn settings (Import seaborn as sns)
sns.set()

# used only for plot x*2
with plt.style.context('dark_background'):
	Plottingcode

############################################
# ADD Sublots: manual + iterative
############################################
# V1
fig = plt.figure()

#221 = 2x2 Subplots, Position 1 (Top left)
ax1 = fig.add_subplot(221)
ax2 = fig.add_subplot(222)
ax3 = fig.add_subplot(223)
ax4 = fig.add_subplot(224)
plt.show()

ax1.plot(x,y1)
ax2.plot(x,y1)
ax3.plot(x,y1)
ax4.plot(x,y1)

# V2
fig, axs = plt.subplots(2,2)
for index, ax in enumerate(fig.axes):
    ax.plot(x, y1)

plt.show()

#################################################
#Seaborn
#################################################
import seaborn as sns

#Grapherzeugung generell
#V0: show all graphs overview for table data
sns.pairplot(iris)

sns.displot(x, y)
sns.displot(data=df)
sns.histplot(data=df)
sns.kdeplot(data=df)
sns.scatterplot(data=df)
sns.barplot(data=df)

#Graphanpassung, alles in einem was man braucht
sns.displot(df, color = "red")
sns.displot(df, x='X-Achse', y='Y-Achse')
sns.displot(df, x='X-Achse', y='Y-Achse',multiple='stack')

#################################################
#Panda Plotting
#################################################
dataframe.plot(kind='scatter', x='dfcolumn1', y='dfcolumn2')
dataframe.plot(kind='bar', x='dfcolumn1', y='dfcolumn2')
dataframe.plot(kind='hist', x='dfcolumn1', y='dfcolumn2')

dataframe.plot.scatter(x='x-Achse',y='y-Achse')
dataframe.plot.bar(x='x-Achse',y='y-Achse')
dataframe.plot.hist(x='x-Achse',y='y-Achse')

#################################################
# SNS
#####################
sns.get_dataset_names()
iris = sns.load_dataset("iris")

#####################
# SKLEARN
#####################
# x= N Dimensional, y = 1 Dimensional
x, y = load_iris(return_X_y=True)
dataset = datasets.load_iris()
x = dataset.data
y = dataset.target
colum_names = iris.feature_names 

################################################################
# Text Analysis
################################################################
from textblob import TextBlob
# Importing Missing packages
    # import nltk
    # nltk.download()

text = "This is a Pfusch Sentence. This is another Pfuscher Sentence "
wiki = TextBlob(text)

wiki.words
wiki.sentences
wiki.noun_phrases
wiki.word_counts['is']
wiki.words.count('is')
wiki.noun_phrases.count('pfusch sentence')


####################################################################   
#Machine Learning: --> #sklearn:x = train, y = test
####################################################################
Supervised (input + output result) --> Classification (discrete) + Regression (continious)
Unsupervised (input)--> Clustering + Association
#########################
#Model Grundstruktur
#########################
a = [1, 2, 3, 4, 5]
b = [2, 4, 6, 8, 10]
X_train, X_test, y_train, y_test = train_test_split(a, b ,test_size=0.25, random_state=0)

#Model and Training Data
nb = ModelFunktion()
nb.fit(X_train, y_train)

# make predictions on test data using test_dtm
preds = nb.predict(X_test)

#########################
# Pipeline and make_pipeline
#########################
model_pipeline = make_pipeline(StandardScaler(), VarianceThreshold(), KNeighborsClassifier())
model_pipeline = pipe = Pipeline([
                                     ('scaler', StandardScaler()),
                                     ('selector', VarianceThreshold()),
                                     ('classifier', KNeighborsClassifier())
                                    ])
model_pipeline.fit(x,y)     
model_pipeline.predict(x2)

# Basic Accuracy Score (for check/comparisons)
accuracy_score(y_values_correctly_labed, y_predicted_by_model)

# Crossvalidation Score, input: model, x_data,y_data, number_of_different_test_train_splits
# kfold vs cv= (StratifiedKFold)
k_fold = KFold(n_splits=5)
cross_val_score(model, x, y, cv=5)
scores = cross_val_score(model, x, y, cv=k_fold)
scores = cross_val_score(pipeline, x, y, cv=k_fold)

#########################
# GridSearchCV: execute model with different list of parameters
#########################
# execute with 2 values linear and rbf for the parameter kernel
parameters = {'kernel': ('linear', 'rbf')}
svc = svm.SVC()
clf = GridSearchCV(svc, parameters)
clf.fit(x, y)
# Check results: list of parameters
clf.cv_results_.keys()
clf.best_estimator_

#########################
#Linear Regression (Classification) --> 0, 1
#########################
lin_reg = LinearRegression()
lin_reg.fit(x, y)

# Predict the values given test set
predictions = lin_reg.predict(X_test)

#########################
#Logistic Regression (Classification) --> 0, 1
#########################
#X = independten feature
#Y = dependent feature
logreg = LogisticRegression(solver='lbfgs')
logreg.fit(x_train,y_train)

# Predict the values given test set
predictions = logreg.predict(x_test)

#########################
#Bayes
#########################
#Model and Training Data
nb = MultinomialNB()
nb.fit(x_traindata, y_traindata)

#make predictions on test data using test_dtm
preds = nb.predict(test_dtm)

#########################
#Decision Tree
#########################
#Model and Training Data
treeclf = DecisionTreeClassifier(max_depth=3, random_state=1)
treeclf.fit(X, y)

preds = treeclf.predict(test_dtm)

#########################
#K-Means
#########################
km = KMeans(n_clusters=3)
km.fit(X)

# save the cluster labels and sort by cluster
clusters = km.labels_

# Chose proper K
# calculate Silhouette Coefficient for K=3
metrics.silhouette_score(X, km.labels_)

#########################
#K-Nearest Neighbor
#########################
#Trainingvalues
knn = KNeighborsClassifier(n_neighbors=1)
knn.fit(X, y)

#Genauigkeit/Score
knn.score(X, y)

preds = knn.predict(testvalues)

####################################################################
#DynamischE Anzahl Parameter
####################################################################
# Dynamic number of unnamed parameters, all packed into 1 tupple: *args
def dyn1(*test):
	print(test[0])
	print(test[1])
	for x in test:
		print(x)


# Dynamic number of named parameters / keyword arguments into 1 Dictionary: *kwargs
def dyn2(**test):
	print(test['a'])
	print(test['b'])
	print(test['c'])
	for x, y in test.items():
		print(x, y)

# Dynamic number number of everything keyword arguments: param + *args + **kwargs
def dyn3(a, *test1, **test2):
	print(a)
	for x in test1:
		print(x)
	for x, y in test2.items():
		print(x, y)

dyn1('kek', 'kek1')
dyn2(a='kek', b='kek2', c='kek3')
dyn3('Param_A', *('tl_1', 'tl_2'), b='Param_B')
dyn3('Param_A', 'tl_1', 'tl_2', b='Param_B')
 
##############################################################################################
list comprehension vs Generator Expression:
	--> list_comprehension --> f�r viele iterationne
	--> iter f�r gro�e Datenmengen
##############################################################################################
symbols = 'ABCDE'
#################################
matrix = [[[1,2],[3,4]]
         ,[[5,6],[7,8]]]
		 
#F�r jede �u�ere Liste         
list_c = [x for x in matrix]

#F�r jedes Element in jeder �u�eren Liste
x2 = [y
	 for x in matrix
	 for y in x]        

#Kartesische Produkt
shirts = [(color,size) 
		   for color in colors
           for size in sizes]

shirts = [color+size for color,size in zip(color,size)]
v_append = [symbol for symbol in symbols symbol == 1 else 2]
v2 = sum(number for number in numbers)
dict_variable = {key:value for (key,value) in dictonary.items()}

###################################
#Join/Split in Strings/Listen
###################################
#Join:
e = ["Fix", "Foxy", "Lupo", "Dr. Knox"]
print(','.join(e))
print(''.join(e))

#Split:
txt = "welcome to the jungle"
x = txt.split()
print(x) #['welcome', 'to', 'the', 'jungle']

txt = "hello, my name is Peter, I am 26 years old"
x = txt.split(", ") #['hello', 'my name is Peter', 'I am 26 years old']

#Split mit mehreren trennern
import re
line = 'asdf fjdk; afed, fjek,asdf, foo'
re.split(r'[;,\s]\s*', line)

###################################
#Lambda: variable1,.. : formel mit variablen
###################################
#Bsp1 lamda entspricht funktion
f = lambda x: x *3 + 7
f(10)
 
#Lambda Verwendung f�r Dynamische Funktion
def multiply(k):
    return lambda x : x * k
    
double = multiply(2)
tripple = multiply(3)

 
####################################################################
#Vererbung: super()
####################################################################
#Oberklasse Person
class Person:
  def __init__(self, fname, lname):
    self.firstname = fname
    self.lastname = lname

#Erbende Klasse Student1:Aufruf �ber Oberklasse.__init__
class Student1(Person):
  def __init__(self, fname, lname, year):
    Person.__init__(self, fname, lname)
    self.graduationyear = year
	
#Erbe �ber super() --> ohne self
class Student2(Person):
  def __init__(self, fname, lname, year):
    super().__init__(fname, lname)
    self.graduationyear = year
 
######################################################################
Vererbung von Python Basisklassen, erlaubt klassen die Benutzung der Basis funktionen
######################################################################
class FrequencyList(list):
    def __init__(self, members):
        super().__init__(members)
f = FrequencyList(['a',['b']])
f.pop()
f.append()
 
####################################################################################################
#Counter(): findet h�ufigsten Wert, order by most to least common
####################################################################################################
from collections import Counter
l = [1,2,2,3]
print(Counter(l))
hochester_wert,Anzahel_Vorkommen = Counter(l).most_common()[0]
 
####################################################################
#Loop with counter
####################################################################
for counter, value in enumerate(some_list):
    print(counter, value)
	
###############################################################################
#Logging
###############################################################################
#Initialisieren Loggers der in Log Datei schreibt, logged default nur wenn Dringlichkeit > Info, deshalb parameter ab Wichtigkeit N
logging.basicConfig(filename = "programm.log", level = logging.INFO)

#Meldungen an Logger �bergeben, an stellen im Programmcode?
logging.log(logging.ERROR, "Fehler REEEEEEEEE")
logging.log(logging.INFO, "NUR INFO REEEEEEEE")
#logging.log(logging.CRITICAL, "KILLT AUSF�HRUNG")   #Auskommentiert, weil ausf�hrung killt

#Deinitialiseren
logging.shutdown()
 

####################################################################################################
#Iterator vs List: List contains Data, iterator yiels/gives data out on the fly
####################################################################################################
#List
my_list = ['a', 'b', 'c', 'd', 'e', 'f', 'g']
print(my_list[3])
 
#Iterator
my_iter = iter(range(100))
print(my_iter, 'does shit only tells its iterator')
print(next(my_iter))
for i in my_iter:
     print(i)
 
####################################################################################################
#Iterator: erzeugt iterierbares objekt, das aber bei z.B. print keine Daten an sich anzeigt
####################################################################################################
from typing import Iterable, Iterator
def g(n: int) -> Iterator[int]:
    i = 0
    while i < n:
        yield i
        i += 1

#x wird iterator = iterierbares objekt, das bei print aber keine Daten zeigt
x = g(5)       
print(x)
#Nur bei iterration
for i in x:
    print(i)
 
####################################################################################################
#Iterateable: Verwendung als Parameter in funktionen wenn man irgend einen Parameter hat von dem man wei� er muss iterierbar sein
#Listen, Tupple, Dictionary,... sind Iterables
####################################################################################################
from typing import Iterable, Iterator,List
def f(ints: Iterable[int]) -> List[str]:
    return [str(x) for x in ints]
 
print(f(range(1, 3)))
  
#######################
#isinstance
#######################
#true
x = isinstance(True, bool)
x = isinstance(5, int)

##############################################################################################
#Zugriffe
##############################################################################################
#CSV/TXT
#Originanpath: 'C:\Python\Data\x.csv'

#Python: 
V1 = 'C:/Python/Data/x.csv'
v2 = 'C:\\Python\\Data\\x.csv'

filename = 'C:/Python/Data Visualisation/Data Visualisation/data/CSV/sitka_weather_2018_simple.csv'
with open(filename,'r') as f:
    csv_reader = csv.reader(f)
    txt_read = f.read()
	txt_lines = f.readlines()
    json_loader = json.load(f)

    for row in reader:
        high = int(row[5])
        low = int(row[6])

--Panda reads
df = pd.read_csv('xx.csv, sep',', header=None)
df = pd.read_excel(xx.xlsx,sheet_name='tabelle1')
df = pd.read_json('xx.json')
 
--API
r = requests.get(url)
response_dict = r.json()

##############################################################################################
# Exceptions: werden bei error immer erstellt, handling erm�glicht verhidnern von Abbruch
# Catch --> How to deal with ERROR --> Code Continues instead of stopping right there
##############################################################################################
#Basic error handling
#############################
# V1:
try:
	#try:Code der Exception erzeugen k�nnte
    print(5/0) 
except NullTeilenError:
    print('Kann nicht durch 0 Teilen')
else:
    print('Wenn kein Error auftritt') 
    
# V2:	
if input == 0:
	raise ZeroDivisionError('Dont divide by 0')
  
# V3:
def troll(input):
    if input == 0:
        raise ZeroDivisionError('ZeroDivisionError: Dont divide by 0')
    else:
        raise ValueError('ValueError: Dont divide by anything')
  
try: 
    troll(0)
except ZeroDivisionError as z:
    print(z)
except ValueError as v:
    print(v)

#############################  
#Custom Exception mit und ohne Argument
#############################
# V1
class CustomError(Exception):
	pass

raise CustomError
raise CustomError('Messge')

# V2
class CustomError(ValueError):
	def __init__(self, message):
		super().__init__('ERROR, falscher parameter: {0}'.format(message))
	
# Raise:
raise CustomError('Paremter f�r Exception')
   
################################################################################################
#Decorator:is a callable that takes another function as argument (the decorated function)
################################################################################################
# Basic without parameter
###########################################################
# Mit @ decorierte funktion wird zum func parameter in der funktion die zum @deco namen passt
# Mehrwert von Aufruf der Funktioniert die dekortiert wurde --> aufruf von decorierte funktioniert f�hrt alles aus deco aus
# �bergabe von Funktionen als Objekte --> add = add() objekt
def deco(func):
    def wrapper():
        return func() * 2
    return wrapper 

#Decorator
@deco
def add():
    return 1+1

#Same as Decorator
x = deco(add)	
	
# Calling add executes deco function and passes add function as its parameter, returns 4
print(add())

###########################################################
# with parameters and return, multiple decorated functions
# on execution, they all become parameter of f1
# functions in classes can also be decorated to become parameters
# class names can also be decorated
	# functions become decorators in class creation
	# the decorated function can be an executeable in the class (self.func = func) --> xx.func()
###########################################################
def f1(func):
	def wrapper(*args, **kwargs):
		x = func(*args, **kwargs)
		return x
	return wrapper
	
@f1
def f(a):
	print(a)

@f1
def add(x,y):
	return x + y

# Runs f1 with function f as parameter, which uses paremters itself
f('Hi')

# Runs f1 function with add as paremter, returns wrapper which returns the return of add
add(3,4)

###########################################################
# Multiple decorations = nested execution
###########################################################
# F1 and F2 are the same, both get @fx decorator
def f1(func):
    def wrapper():
        return func() * 2
    return wrapper 
	
def f2(func):
    def wrapper():
        return func() * 2
    return wrapper 

#Example 1 from above, this equals: x = f1(f)
@f1
def	f():
	return 2
	
#Example 2, multiple decoratos, this equals: x = f2(f1(f))
@f1
@f2
def f():
	return 2

######################################################################
# @property: property() is a built in function
# which gets functions as parameters by @property decoration
# Reasons to use getter/setter:
	# allows more complex logic (if...) than just simple ob.attr = attr
######################################################################
class Whatever:
    def __init__(self,x):
        self.x = x
        
    # Getter
    def getter1(self):
        return self.x

    @property
    def getter2(self):
        return self.x

    # Setter
    def setter1(self,new_value):
        self.x = new_value

    @getter2.setter
    def setter2(self,new_value):
        self.x = new_value

# Call as function and as decorated object
# Setter takes the @property getter function
kek = Whatever(5)
print(kek.getter1())
print(kek.getter2)

#Setter1, Setter2
kek.setter1(69)
kek.setter2 = 420
print(kek.getter1())
print(kek.getter2)
		
###############################################################################
# Abstract classes: force implementation of methods + attributes
###############################################################################
from __future__ import annotations
from abc import ABC, abstractmethod
from collections.abc import Sequence

class AbsClass(ABC):
	@abstractmethod
	def abmethod(self):
		pass

	@property
	@abstractmethod
	def absset(self):
		pass

class NonAbsClass(AbsClass):
	absset = 'property set'
	def abmethod(self):
		print('implementation')


c = NonAbsClass()

###############################################################################
# Overload: define return type depending on input
# Example is BS, but the this is just for understand what overload is used for
###############################################################################
from typing import overload

@overload
def samename(in_put: int) ->int:
	...

@overload
def samename(in_put: float) -> float:
	...

def samename(in_put: int | float) -> int | float:
	if isinstance(in_put, int):
		print('integer')
		return in_put
	else:
		print('float')
		return in_put

x = samename(1)
y = samename(0.5)
print(type(x))
print(type(y))

####################################################################
#sys.argv
####################################################################
#Ecuted using parameters: python filenaname.py 1 2 3
#Get Parameters of given to the execution
import sys
print(sys.argv)             #List of: Path/filename.py + Arguments (Path/filename.py,1,2,3)
print(sys.argv[0])          #Filepath/filename.py
print(len(sys.argv))        #4 = File + Parameters

####################################################################	
#Testing: checking results for:
#variables, class attributes or functions with return
####################################################################
# unittest
assertEqual(1,1)

# pytest
assert 1 == 1.0

###########################################
# regular expression (Regex)
	# fullmatch: does full string match conditions
	# findall: returns whole substring matching conditions
###########################################
import re

# simple all match check
if re.fullmatch('[A-Za-z0-9_]+', check_string):
	print(check_string, ' is valid')
else:
	print(check_string, ' is not valid') 
	
# check all with separator
if re.fullmatch('[A-Za-z0-9_]+@[A-Za-z0-9_]+.[A-Za-z0-9_]+', check_string):
	print(check_string, ' is valid')
else:
	print(check_string, ' is not valid') 
	
####################################################################	
#Python Main:
####################################################################
#__name__ variable: defaultwert is __main__
print("The value of __name__ is:", repr(__name__))
print("wenn .py file importiert wird ist der filename __name__:", repr(__name__))

#File1.py
print('Wird bei import und bei Dateiausf�hrung ausgef�rt')
def ff():
    print("Wird nur ausgef�hrt wenn Datei selbst ausgef�rht wird, nicht bei import")

if __name__ == "__main__":
    ff()

#File2.py
import file2.py
print('F�hrt print 1 aus File1 aus, nicht ff() weil __name__ = File1 und nicht main')

#Obere Code f�hrt main aus wenn Datei ausgepf�hrt wird, wenn importiert wird nicht!
#denn dann .py filename, wenn .py importiert wird wird code ausgef�hrt wenn nicht in klassen/func

